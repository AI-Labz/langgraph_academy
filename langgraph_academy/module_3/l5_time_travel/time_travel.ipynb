{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Travel\n",
    "\n",
    "## Review\n",
    "\n",
    "We disussed motivations for human-in-the-loop:\n",
    "\n",
    "- `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action.\n",
    "- `Debugging` - We can rewind the graph to reproduce or avoid issues.\n",
    "- `Editing` - You can also modify the state.\n",
    "\n",
    "We showed how breakpoints can stop the graph at specific nodes.\n",
    "\n",
    "Then we showed how to proceed with human approval or directly edit the graph state with human feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "Now, let's show how LangGraph supports debugging by viewing, re-playing, and even forking from past states.\n",
    "\n",
    "We call this `time travel`.\n",
    "\n",
    "Let's build our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import display, Image\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1-tool\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tools\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "def add(a: int, b:  int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def divide(a:  int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiply, add, divide]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System Message\n",
    "system_message = SystemMessage(content=\"You are a helpful AI assistant tasked to perform arithmetic operations on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([system_message] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define Nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\":\"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (4a64a1fc-a3d8-4bcd-984d-92ddec7ae8b5)\n",
      " Call ID: 4a64a1fc-a3d8-4bcd-984d-92ddec7ae8b5\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3.\"}\n",
    "\n",
    "# Run the Graph\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing History\n",
    "\n",
    "We can use `get_state` to look at the **current** state of our graph, given the `thread_id`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:07:57.579064Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7004872200, 'load_duration': 5656895800, 'prompt_eval_count': 340, 'prompt_eval_duration': 426000000, 'eval_count': 22, 'eval_duration': 446000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-a9b17582-427d-4d81-9a29-4af526fff9aa-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '4a64a1fc-a3d8-4bcd-984d-92ddec7ae8b5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 340, 'output_tokens': 22, 'total_tokens': 362}), ToolMessage(content='6', name='multiply', id='5735703e-2dc3-4f3b-b5bc-1737a6845d7e', tool_call_id='4a64a1fc-a3d8-4bcd-984d-92ddec7ae8b5'), AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={}, response_metadata={'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:07:57.9007194Z', 'done': True, 'done_reason': 'stop', 'total_duration': 310883000, 'load_duration': 14510300, 'prompt_eval_count': 144, 'prompt_eval_duration': 16000000, 'eval_count': 14, 'eval_duration': 278000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, id='run-47c6c37d-480c-4d73-98f4-c0a55c6fe0a0-0', usage_metadata={'input_tokens': 144, 'output_tokens': 14, 'total_tokens': 158})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd3395-bd4a-61b3-8003-320e40fd9fb3'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={}, response_metadata={'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:07:57.9007194Z', 'done': True, 'done_reason': 'stop', 'total_duration': 310883000, 'load_duration': 14510300, 'prompt_eval_count': 144, 'prompt_eval_duration': 16000000, 'eval_count': 14, 'eval_duration': 278000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, id='run-47c6c37d-480c-4d73-98f4-c0a55c6fe0a0-0', usage_metadata={'input_tokens': 144, 'output_tokens': 14, 'total_tokens': 158})]}}, 'thread_id': '1', 'step': 3, 'parents': {}}, created_at='2025-01-15T12:07:57.903301+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd3395-ba47-68a2-8002-f27e2bb0320b'}}, tasks=())\n"
     ]
    }
   ],
   "source": [
    "state = graph.get_state({\"configurable\":{\"thread_id\":\"1\"}})\n",
    "pprint(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also browse the state history of our agent.\n",
    "\n",
    "`get_state_history` let us get the state at all prior steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [s for s in graph.get_state_history(thread)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the history. As we can see the most recent message is the first one in the list of `StateSnapshot` (A wrapper for a checkpoint).\n",
    "\n",
    "And each StateSnapshot have a checkpoint id, the number of messages accumulated in each super-step, and the next node to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd3395-bd4a-61b3-8003-320e40fd9fb3\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-ba47-68a2-8002-f27e2bb0320b\n",
      "Num Messages:  3 Next:  ('assistant',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-ba3e-66a6-8001-01605bb15940\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-58ed-67be-8000-af85423b55e4\n",
      "Num Messages:  1 Next:  ('assistant',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-58e6-6253-bfff-91cdf8156ae4\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in all_states:\n",
    "    print(\"ID: \", state.config[\"configurable\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of this list is the current state, just as we got from `get_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Multiply 2 and 3.\n",
      "\n",
      "6\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "current = all_states[0]\n",
    "print(\"Num Messages: \", len(current.values[\"messages\"]), \"Next: \", current.next)\n",
    "print(\"-\" * 80)\n",
    "for m in current.values[\"messages\"]:\n",
    "    print(m.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything above can be visualized here:\n",
    "\n",
    "<center><img src=\"../../../assets/get_state.jpg\" width=900 alt=\"get_state\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaying\n",
    "\n",
    "We can re-run our agent from any of the prior steps.\n",
    "\n",
    "<center><img src=\"../../../assets/re_playing.jpg\" width=900 alt=\"replaying\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we saw that by passing an input as `None` to stream with the `thread_id`, the graph pick up the execution from the current state.\n",
    "\n",
    "But, what if we set a `checkpoint_id` as well? \n",
    "\n",
    "Then we will re-play the graph from this checkpoint till the current checkpoint state.\n",
    "\n",
    "This means that, the graph won't execute from `__start__` node till the end node, this is a re-execution.\n",
    "\n",
    "Instead, the graph will execute the subsequential nodes starting from the node whose `checkpoint_id` was select to start from.\n",
    "\n",
    "Then it will add these new subsequential checkpoints to the checkpoint history.\n",
    "\n",
    "So, to catch up:\n",
    "\n",
    "If we have a Graph with nodes 1, 2, 3, and 4 and the path of execution is `1 -> 2 -> 3 -> 4`, then:\n",
    "\n",
    "- Replay: By selecting checkpoint from node `2`, the graph will execute `2 -> 3 -> 4` and the checkpoint history will be `1, 2, 3, 4, 2, 3, 4`\n",
    "- Rexecute: it will execute the graph from start, so `1 -> 2 -> 3 -> 4`, hence the checkpoint history will be: `1, 2, 3, 4, 1, 2, 3, 4`\n",
    "\n",
    "Let's look back at the step that received human input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = all_states[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 2 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the next node to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistant',)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also get the config, which tell us the `checkpoint_id` as well as the `thread_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efd3395-58ed-67be-8000-af85423b55e4'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replay from here, we simply pass the config back to the agent!\n",
    "\n",
    "The graph knows that this checkpoint has already been executed.\n",
    "\n",
    "It just re-plays from this checkpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (be008db3-9412-4009-82f4-a0b65f53e40c)\n",
      " Call ID: be008db3-9412-4009-82f4-a0b65f53e40c\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, config=to_replay.config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the history and as we selected the checkpoint from the node `assistant`, we will see that the appended checkpoints are `assistant`, `tools` and `assistant` again, meaning that only nodes starting from the checkpoint were executed and their produced checkpoints were added to the historyof checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd33aa-ee18-601c-8003-5aee3f322353\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd33aa-eb08-64ac-8002-12a8e3d86859\n",
      "Num Messages:  3 Next:  ('assistant',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd33aa-eb03-6686-8001-bf7599a5e5af\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-bd4a-61b3-8003-320e40fd9fb3\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-ba47-68a2-8002-f27e2bb0320b\n",
      "Num Messages:  3 Next:  ('assistant',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-ba3e-66a6-8001-01605bb15940\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-58ed-67be-8000-af85423b55e4\n",
      "Num Messages:  1 Next:  ('assistant',)\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-58e6-6253-bfff-91cdf8156ae4\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in graph.get_state_history(thread):\n",
    "    print(\"ID: \", state.config[\"configurable\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forking\n",
    "\n",
    "What if we want to run from that same step, but with a different input! This is forking.\n",
    "\n",
    "<center><img src=\"../../../assets/forking.jpg\" width=900 alt=\"forking\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case you update a state at a certain checkpoint by passing a new `state`, given the `checkpoint_id` and `thread_id` of this state.\n",
    "\n",
    "When you do that, you fork your graph, meaning that you create a new checkpoint as previously saw in replay, but now the graph will reexecutewhen you stream/invoke the graph.\n",
    "\n",
    "Because the graph knows that the state changed at that `checkpoint_id`, so it needs to be re-executed to get the next states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 2 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork = all_states[-2]\n",
    "to_fork.values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efd3395-58ed-67be-8000-af85423b55e4'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the state at this checkpoint.\n",
    "\n",
    "We can just run `update_state` with the `checkpoint_id` supplied.\n",
    "\n",
    "Remember how our reducer on `messages` works:\n",
    "\n",
    "- It will append, unless we supply a message ID.\n",
    "- We supply the message ID to overwritte the message, rather than appending to state!\n",
    "\n",
    "So, to overwritte the message, we just supply the message ID, which we have with `to_fork.values[\"messages\"].id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_config = graph.update_state(to_fork.config, {\"messages\":[HumanMessage(content=\"Multiply 5 and 3.\", id=to_fork.values[\"messages\"][0].id)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efd33c0-c198-6ec3-8001-0dff22e97c8e'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fork_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see a new checkpoint added to a state history (length 6 now, versus 5 above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states = [s for s in graph.get_state_history(thread)]\n",
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd33c0-c198-6ec3-8001-0dff22e97c8e\n",
      "Message:  Multiply 5 and 3. Id:  804d2fb4-57b0-45a1-8461-55477950ba2a\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd33aa-ee18-601c-8003-5aee3f322353\n",
      "Message:  The result of multiplying 2 and 3 is 6. Id:  run-cfebe66d-d07e-4c3c-8b7c-ce2c9761f899-0\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd33aa-eb08-64ac-8002-12a8e3d86859\n",
      "Message:  6 Id:  10f665a1-7997-475f-9759-276820cfbcb8\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd33aa-eb03-6686-8001-bf7599a5e5af\n",
      "Message:   Id:  run-883d7c87-c68c-4f9e-9703-139bcb772fe0-0\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-bd4a-61b3-8003-320e40fd9fb3\n",
      "Message:  The result of multiplying 2 and 3 is 6. Id:  run-47c6c37d-480c-4d73-98f4-c0a55c6fe0a0-0\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-ba47-68a2-8002-f27e2bb0320b\n",
      "Message:  6 Id:  5735703e-2dc3-4f3b-b5bc-1737a6845d7e\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-ba3e-66a6-8001-01605bb15940\n",
      "Message:   Id:  run-a9b17582-427d-4d81-9a29-4af526fff9aa-0\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-58ed-67be-8000-af85423b55e4\n",
      "Message:  Multiply 2 and 3. Id:  804d2fb4-57b0-45a1-8461-55477950ba2a\n",
      "--------------------------------------------------------------------------------\n",
      "ID:  1efd3395-58e6-6253-bfff-91cdf8156ae4\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in all_states:\n",
    "    print(\"ID: \", state.config[\"configurable\"][\"checkpoint_id\"])\n",
    "    #print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    if len(state.values[\"messages\"]) > 0:\n",
    "        print(\"Message: \", state.values[\"messages\"][-1].content, \"Id: \", state.values[\"messages\"][-1].id)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd33c0-c198-6ec3-8001-0dff22e97c8e'}}, metadata={'source': 'update', 'writes': {'__start__': {'messages': [HumanMessage(content='Multiply 5 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a')]}}, 'thread_id': '1', 'step': 1, 'parents': {}, 'checkpoint_ns': '', 'checkpoint_id': '1efd3395-58ed-67be-8000-af85423b55e4'}, created_at='2025-01-15T12:27:12.627475+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd3395-58ed-67be-8000-af85423b55e4'}}, tasks=(PregelTask(id='2179bf31-bd2c-8197-9ac1-ea5c6e2f2972', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),))\n"
     ]
    }
   ],
   "source": [
    "new_state = all_states[0]\n",
    "pprint(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a new, forked checkpoint.\n",
    "\n",
    "But, the metadata -e.g., where to go next - is preserved!\n",
    "\n",
    "We can see the current state of our agent has been updated with our fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiply 5 and 3.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state.values[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd33c0-c198-6ec3-8001-0dff22e97c8e'}}, metadata={'source': 'update', 'writes': {'__start__': {'messages': [HumanMessage(content='Multiply 5 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a')]}}, 'thread_id': '1', 'step': 1, 'parents': {}, 'checkpoint_ns': '', 'checkpoint_id': '1efd3395-58ed-67be-8000-af85423b55e4'}, created_at='2025-01-15T12:27:12.627475+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd3395-58ed-67be-8000-af85423b55e4'}}, tasks=(PregelTask(id='2179bf31-bd2c-8197-9ac1-ea5c6e2f2972', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),))\n"
     ]
    }
   ],
   "source": [
    "pprint(graph.get_state(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we stream, the graph knows this checkpoint has never been executed.\n",
    "\n",
    "So, the graph runs, rather than simply re-playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 3.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (01894159-c5d3-423b-b8d5-5afe778bdcbe)\n",
      " Call ID: 01894159-c5d3-423b-b8d5-5afe778bdcbe\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "15\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 5 and 3 is 15.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3.', additional_kwargs={}, response_metadata={}, id='804d2fb4-57b0-45a1-8461-55477950ba2a'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:45:58.8401143Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3582913500, 'load_duration': 2375998200, 'prompt_eval_count': 340, 'prompt_eval_duration': 250000000, 'eval_count': 22, 'eval_duration': 436000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-9be0be99-d829-4201-82bc-331f990a1466-0', tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 3}, 'id': '01894159-c5d3-423b-b8d5-5afe778bdcbe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 340, 'output_tokens': 22, 'total_tokens': 362}), ToolMessage(content='15', name='multiply', id='b62803ac-86bc-4dd3-9de2-7d90eb0064d3', tool_call_id='01894159-c5d3-423b-b8d5-5afe778bdcbe'), AIMessage(content='The result of multiplying 5 and 3 is 15.', additional_kwargs={}, response_metadata={'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:45:59.1563165Z', 'done': True, 'done_reason': 'stop', 'total_duration': 309098700, 'load_duration': 15247300, 'prompt_eval_count': 144, 'prompt_eval_duration': 11000000, 'eval_count': 14, 'eval_duration': 279000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 5 and 3 is 15.', 'images': None, 'tool_calls': None}}, id='run-d7d6a357-36f4-4270-bda2-13bd7d54cdfd-0', usage_metadata={'input_tokens': 144, 'output_tokens': 14, 'total_tokens': 158})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd33ea-b907-6926-8004-dfcbeabb3e2c'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result of multiplying 5 and 3 is 15.', additional_kwargs={}, response_metadata={'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:45:59.1563165Z', 'done': True, 'done_reason': 'stop', 'total_duration': 309098700, 'load_duration': 15247300, 'prompt_eval_count': 144, 'prompt_eval_duration': 11000000, 'eval_count': 14, 'eval_duration': 279000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 5 and 3 is 15.', 'images': None, 'tool_calls': None}}, id='run-d7d6a357-36f4-4270-bda2-13bd7d54cdfd-0', usage_metadata={'input_tokens': 144, 'output_tokens': 14, 'total_tokens': 158})]}}, 'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd33c0-c198-6ec3-8001-0dff22e97c8e', 'step': 4, 'parents': {}}, created_at='2025-01-15T12:45:59.157994+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efd33ea-b60b-6f7b-8003-5e59c0407e6c'}}, tasks=())\n"
     ]
    }
   ],
   "source": [
    "pprint(graph.get_state(thread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd33ea-b907-6926-8004-dfcbeabb3e2c\n",
      "Num Messages:  4 Next:  ()\n",
      "ID:  1efd33ea-b60b-6f7b-8003-5e59c0407e6c\n",
      "Num Messages:  3 Next:  ('assistant',)\n",
      "ID:  1efd33ea-b604-6b88-8002-d17d7ef17b14\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "ID:  1efd33c0-c198-6ec3-8001-0dff22e97c8e\n",
      "Num Messages:  1 Next:  ('assistant',)\n",
      "ID:  1efd33aa-ee18-601c-8003-5aee3f322353\n",
      "Num Messages:  4 Next:  ()\n",
      "ID:  1efd33aa-eb08-64ac-8002-12a8e3d86859\n",
      "Num Messages:  3 Next:  ('assistant',)\n",
      "ID:  1efd33aa-eb03-6686-8001-bf7599a5e5af\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "ID:  1efd3395-bd4a-61b3-8003-320e40fd9fb3\n",
      "Num Messages:  4 Next:  ()\n",
      "ID:  1efd3395-ba47-68a2-8002-f27e2bb0320b\n",
      "Num Messages:  3 Next:  ('assistant',)\n",
      "ID:  1efd3395-ba3e-66a6-8001-01605bb15940\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "ID:  1efd3395-58ed-67be-8000-af85423b55e4\n",
      "Num Messages:  1 Next:  ('assistant',)\n",
      "ID:  1efd3395-58e6-6253-bfff-91cdf8156ae4\n",
      "Num Messages:  0 Next:  ('__start__',)\n"
     ]
    }
   ],
   "source": [
    "for state in graph.get_state_history(thread):\n",
    "    print(\"ID: \", state.config[\"configurable\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Travel with API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the URL for the local deployment from Studio\n",
    "\n",
    "To get it let's run `langgraph dev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://localhost:2024\")\n",
    "assistant_id = \"react\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-playing\n",
    "\n",
    "Let's run our agent streaming `updates` to the state of the graph after each node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Assistant Node --------------------\n",
      "{'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:56:02.332204Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3395942700, 'load_duration': 1849813300, 'prompt_eval_count': 376, 'prompt_eval_duration': 370000000, 'eval_count': 22, 'eval_duration': 479000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-e861bdb5-8ddb-4be1-a687-c3a88a3e5740-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'ae534cef-9ce8-4495-9e17-90661207af20', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}}\n",
      "-------------------- Tool Node --------------------\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '627905a7-038f-4f46-a765-33c59e9ce65b', 'tool_call_id': 'ae534cef-9ce8-4495-9e17-90661207af20', 'artifact': None, 'status': 'success'}\n",
      "-------------------- Assistant Node --------------------\n",
      "{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T12:56:02.6657486Z', 'done': True, 'done_reason': 'stop', 'total_duration': 319829300, 'load_duration': 22392800, 'prompt_eval_count': 162, 'prompt_eval_duration': 9000000, 'eval_count': 14, 'eval_duration': 285000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-c8662eb1-71ff-452f-9ca2-3d2d7ec77e7c-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 162, 'output_tokens': 14, 'total_tokens': 176}}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3.\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"], assistant_id, input=initial_input,stream_mode=\"updates\"\n",
    "):\n",
    "    if chunk.data:\n",
    "        assistant_node = chunk.data.get(\"assistant\",{}).get(\"messages\",[])\n",
    "        tool_node = chunk.data.get(\"tools\",{}).get(\"messages\",[])\n",
    "        if assistant_node:\n",
    "            print(\"-\"*20 + \" Assistant Node \" + \"-\"*20)\n",
    "            print(assistant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\"*20 + \" Tool Node \" + \"-\"*20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simply look at `replaying` from a specified checkpoint.\n",
    "\n",
    "We need to pass the `checkpoint_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd3401-3498-65ed-8003-eaf0c3b1e2c7\n",
      "Num Messages:  4 Next:  []\n",
      "ID:  1efd3401-3172-69b9-8002-3a2cadcf983a\n",
      "Num Messages:  3 Next:  ['assistant']\n",
      "ID:  1efd3401-3169-66ad-8001-a1d86eaa0e87\n",
      "Num Messages:  2 Next:  ['tools']\n",
      "ID:  1efd3400-fd6b-6881-8000-2e50abbbd8ce\n",
      "Num Messages:  1 Next:  ['assistant']\n",
      "ID:  1efd3400-fd61-6c13-bfff-20b7258e52cc\n",
      "Num Messages:  0 Next:  ['__start__']\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    print(\"ID: \", state[\"checkpoint\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state[\"values\"][\"messages\"]), \"Next: \", state[\"next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 2 and 3.',\n",
       "    'additional_kwargs': {'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'example': False},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': 'cc5bd1d9-5b7b-407a-81fe-ca49ad5fc429',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': 'c10a5720-6d54-dd40-07a2-438ca1533bc4',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': {'messages': [{'content': '',\n",
       "      'additional_kwargs': {},\n",
       "      'response_metadata': {'model': 'llama3.1-tool',\n",
       "       'created_at': '2025-01-15T12:56:02.332204Z',\n",
       "       'done': True,\n",
       "       'done_reason': 'stop',\n",
       "       'total_duration': 3395942700,\n",
       "       'load_duration': 1849813300,\n",
       "       'prompt_eval_count': 376,\n",
       "       'prompt_eval_duration': 370000000,\n",
       "       'eval_count': 22,\n",
       "       'eval_duration': 479000000,\n",
       "       'message': {'role': 'assistant',\n",
       "        'content': '',\n",
       "        'images': None,\n",
       "        'tool_calls': None}},\n",
       "      'type': 'ai',\n",
       "      'name': None,\n",
       "      'id': 'run-e861bdb5-8ddb-4be1-a687-c3a88a3e5740-0',\n",
       "      'example': False,\n",
       "      'tool_calls': [{'name': 'multiply',\n",
       "        'args': {'a': 2, 'b': 3},\n",
       "        'id': 'ae534cef-9ce8-4495-9e17-90661207af20',\n",
       "        'type': 'tool_call'}],\n",
       "      'invalid_tool_calls': [],\n",
       "      'usage_metadata': {'input_tokens': 376,\n",
       "       'output_tokens': 22,\n",
       "       'total_tokens': 398}}]}}],\n",
       " 'metadata': {'langgraph_auth_user': None,\n",
       "  'langgraph_auth_user_id': '',\n",
       "  'graph_id': 'react',\n",
       "  'assistant_id': '166c0d22-706c-5a5b-9027-ea37f7308a85',\n",
       "  'user_id': '',\n",
       "  'created_by': 'system',\n",
       "  'run_attempt': 1,\n",
       "  'langgraph_version': '0.2.60',\n",
       "  'langgraph_plan': 'developer',\n",
       "  'langgraph_host': 'self-hosted',\n",
       "  'run_id': '1efd3400-fb1f-6568-932f-64df3849096f',\n",
       "  'thread_id': 'f3a25e49-cfa0-4856-a18e-987ef63d7861',\n",
       "  'source': 'loop',\n",
       "  'writes': None,\n",
       "  'step': 0,\n",
       "  'parents': {}},\n",
       " 'created_at': '2025-01-15T12:55:56.887257+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1efd3400-fd6b-6881-8000-2e50abbbd8ce',\n",
       "  'thread_id': 'f3a25e49-cfa0-4856-a18e-987ef63d7861',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1efd3400-fd61-6c13-bfff-20b7258e52cc',\n",
       "  'thread_id': 'f3a25e49-cfa0-4856-a18e-987ef63d7861',\n",
       "  'checkpoint_ns': ''},\n",
       " 'checkpoint_id': '1efd3400-fd6b-6881-8000-2e50abbbd8ce',\n",
       " 'parent_checkpoint_id': '1efd3400-fd61-6c13-bfff-20b7258e52cc'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay = states[-2]\n",
    "to_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stream with `stream_mode=\"values\"` to see the full state at every node as we replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "{'run_id': '1efd343d-1b91-6721-ae54-3e3cd23ad99e', 'attempt': 1}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3.', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cc5bd1d9-5b7b-407a-81fe-ca49ad5fc429', 'example': False}]}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3.', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cc5bd1d9-5b7b-407a-81fe-ca49ad5fc429', 'example': False}, {'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:22:56.0570763Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3270667100, 'load_duration': 2093886700, 'prompt_eval_count': 376, 'prompt_eval_duration': 254000000, 'eval_count': 22, 'eval_duration': 440000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-1113104b-e48a-41e9-b111-2bb19288a653-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '669ad39d-7054-468a-892c-2f5db3b24a0f', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}}]}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3.', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cc5bd1d9-5b7b-407a-81fe-ca49ad5fc429', 'example': False}, {'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:22:56.0570763Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3270667100, 'load_duration': 2093886700, 'prompt_eval_count': 376, 'prompt_eval_duration': 254000000, 'eval_count': 22, 'eval_duration': 440000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-1113104b-e48a-41e9-b111-2bb19288a653-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '669ad39d-7054-468a-892c-2f5db3b24a0f', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'f7e0064d-f8a5-4297-964d-3da8b2453b1b', 'tool_call_id': '669ad39d-7054-468a-892c-2f5db3b24a0f', 'artifact': None, 'status': 'success'}]}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3.', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'cc5bd1d9-5b7b-407a-81fe-ca49ad5fc429', 'example': False}, {'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:22:56.0570763Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3270667100, 'load_duration': 2093886700, 'prompt_eval_count': 376, 'prompt_eval_duration': 254000000, 'eval_count': 22, 'eval_duration': 440000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-1113104b-e48a-41e9-b111-2bb19288a653-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '669ad39d-7054-468a-892c-2f5db3b24a0f', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'f7e0064d-f8a5-4297-964d-3da8b2453b1b', 'tool_call_id': '669ad39d-7054-468a-892c-2f5db3b24a0f', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:22:56.3849087Z', 'done': True, 'done_reason': 'stop', 'total_duration': 311334400, 'load_duration': 15570700, 'prompt_eval_count': 162, 'prompt_eval_duration': 8000000, 'eval_count': 14, 'eval_duration': 286000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-d8e828fa-b81f-465d-90e5-41c31569e7dd-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 162, 'output_tokens': 14, 'total_tokens': 176}}]}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(thread['thread_id'], assistant_id, input=None,stream_mode=\"values\", checkpoint_id=to_replay['checkpoint_id']):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let s see the history! We can see that it's adding the new checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd343d-5236-60c8-8003-f95cff888206\n",
      "Num Messages:  4 Next:  []\n",
      "ID:  1efd343d-4f22-6e9a-8002-0b8bba7e1f92\n",
      "Num Messages:  3 Next:  ['assistant']\n",
      "ID:  1efd343d-4f18-65f5-8001-3656eea01e9f\n",
      "Num Messages:  2 Next:  ['tools']\n",
      "ID:  1efd3401-3498-65ed-8003-eaf0c3b1e2c7\n",
      "Num Messages:  4 Next:  []\n",
      "ID:  1efd3401-3172-69b9-8002-3a2cadcf983a\n",
      "Num Messages:  3 Next:  ['assistant']\n",
      "ID:  1efd3401-3169-66ad-8001-a1d86eaa0e87\n",
      "Num Messages:  2 Next:  ['tools']\n",
      "ID:  1efd3400-fd6b-6881-8000-2e50abbbd8ce\n",
      "Num Messages:  1 Next:  ['assistant']\n",
      "ID:  1efd3400-fd61-6c13-bfff-20b7258e52cc\n",
      "Num Messages:  0 Next:  ['__start__']\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    print(\"ID: \", state[\"checkpoint\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state[\"values\"][\"messages\"]), \"Next: \", state[\"next\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forking\n",
    "\n",
    "Now, let's look at forking!\n",
    "\n",
    "Let's get the same step as we worked with above, the human input.\n",
    "\n",
    "Let's create a new thread with our agent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Assistant Node --------------------\n",
      "{'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:30:51.7516223Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3055357400, 'load_duration': 1838340600, 'prompt_eval_count': 376, 'prompt_eval_duration': 258000000, 'eval_count': 22, 'eval_duration': 439000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-c3c581d4-a63b-4139-89f9-b6efc232a575-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '4fb62019-a9c7-4662-bb16-433717689875', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}}\n",
      "-------------------- Tool Node --------------------\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'cfc19c50-6edb-49db-9014-ff18fda60fdb', 'tool_call_id': '4fb62019-a9c7-4662-bb16-433717689875', 'artifact': None, 'status': 'success'}\n",
      "-------------------- Assistant Node --------------------\n",
      "{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:30:52.0998821Z', 'done': True, 'done_reason': 'stop', 'total_duration': 322713400, 'load_duration': 27533900, 'prompt_eval_count': 162, 'prompt_eval_duration': 17000000, 'eval_count': 14, 'eval_duration': 274000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-81edd66f-7732-416d-a0ec-25eb5c53f0e1-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 162, 'output_tokens': 14, 'total_tokens': 176}}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3.\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id,\n",
    "    input=initial_input,\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    if chunk.data:\n",
    "        assistant_node = chunk.data.get(\"assistant\",{}).get(\"messages\",[])\n",
    "        tool_node = chunk.data.get(\"tools\",{}).get(\"messages\",[])\n",
    "        if assistant_node:\n",
    "            print(\"-\"*20 + \" Assistant Node \" + \"-\"*20)\n",
    "            print(assistant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\"*20 + \" Tool Node \" + \"-\"*20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fork = states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Multiply 2 and 3.',\n",
       "   'additional_kwargs': {'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'example': False},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': '7c3e5bd3-76be-4114-ba81-ddeac0ac79a0',\n",
       "   'example': False}]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7c3e5bd3-76be-4114-ba81-ddeac0ac79a0'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"values\"][\"messages\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assistant']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1efd344e-d704-6a39-8000-cb5806fd96a3'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"checkpoint_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's edit the state.\n",
    "\n",
    "Remember how our reducer onn `messages` works:\n",
    "\n",
    "- It will append, unless we supply a message ID.\n",
    "- We supply the message ID to overwritte the message, rather than appending to state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_input = {\"messages\": HumanMessage(content=\"Multiply 3 and 5.\", id=to_fork[\"values\"][\"messages\"][0][\"id\"])}\n",
    "\n",
    "forked_config = await client.threads.update_state(\n",
    "    thread[\"thread_id\"], forked_input, checkpoint_id=to_fork[\"checkpoint_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'checkpoint': {'checkpoint_id': '1efd3459-505d-64f3-8001-12b64d1efb38',\n",
      "                'checkpoint_ns': '',\n",
      "                'thread_id': '572335f4-29f9-471f-b421-f02cc01bd6de'},\n",
      " 'checkpoint_id': '1efd3459-505d-64f3-8001-12b64d1efb38',\n",
      " 'configurable': {'checkpoint_id': '1efd3459-505d-64f3-8001-12b64d1efb38',\n",
      "                  'checkpoint_ns': '',\n",
      "                  'thread_id': '572335f4-29f9-471f-b421-f02cc01bd6de'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(forked_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd3459-505d-64f3-8001-12b64d1efb38\n",
      "Num Messages:  1 Next:  ['assistant']\n",
      "ID:  1efd344f-0af7-681e-8003-0033b015937c\n",
      "Num Messages:  4 Next:  []\n",
      "ID:  1efd344f-07cc-6abc-8002-2548b5c96f0c\n",
      "Num Messages:  3 Next:  ['assistant']\n",
      "ID:  1efd344f-07a1-6eb3-8001-5d5bfa89b4fc\n",
      "Num Messages:  2 Next:  ['tools']\n",
      "ID:  1efd344e-d704-6a39-8000-cb5806fd96a3\n",
      "Num Messages:  1 Next:  ['assistant']\n",
      "ID:  1efd344e-d6fd-621c-bfff-cf5605717a9c\n",
      "Num Messages:  0 Next:  ['__start__']\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    print(\"ID: \", state[\"checkpoint\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state[\"values\"][\"messages\"]), \"Next: \", state[\"next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'additional_kwargs': {'additional_kwargs': {},\n",
      "                                     'example': False,\n",
      "                                     'response_metadata': {}},\n",
      "               'content': 'Multiply 3 and 5.',\n",
      "               'example': False,\n",
      "               'id': '7c3e5bd3-76be-4114-ba81-ddeac0ac79a0',\n",
      "               'name': None,\n",
      "               'response_metadata': {},\n",
      "               'type': 'human'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(states[0]['values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rerun, we pass in the checkpoint id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Assistant Node --------------------\n",
      "{'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:41:15.4201885Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3043156500, 'load_duration': 1851209400, 'prompt_eval_count': 376, 'prompt_eval_duration': 249000000, 'eval_count': 22, 'eval_duration': 438000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-08acfa66-a907-4965-895a-4e9190df357a-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'e21afcfa-7e3f-4d2d-bd92-16619a296255', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}}\n",
      "-------------------- Tool Node --------------------\n",
      "{'content': '15', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '95028a5d-eaf8-49cb-9489-3badaf35476e', 'tool_call_id': 'e21afcfa-7e3f-4d2d-bd92-16619a296255', 'artifact': None, 'status': 'success'}\n",
      "-------------------- Assistant Node --------------------\n",
      "{'content': 'The result of multiplying 3 and 5 is 15.', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-15T13:41:15.7596218Z', 'done': True, 'done_reason': 'stop', 'total_duration': 324408400, 'load_duration': 25646500, 'prompt_eval_count': 162, 'prompt_eval_duration': 8000000, 'eval_count': 14, 'eval_duration': 286000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 3 and 5 is 15.', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-a03ff941-becf-4f4b-bdf2-76fbc901f4ed-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 162, 'output_tokens': 14, 'total_tokens': 176}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread['thread_id'],\n",
    "    assistant_id,\n",
    "    input=None,\n",
    "    stream_mode=\"updates\",\n",
    "    checkpoint_id=forked_config['checkpoint_id']\n",
    "):\n",
    "    if chunk.data:\n",
    "        assistant_node = chunk.data.get(\"assistant\",{}).get(\"messages\",[])\n",
    "        tool_node = chunk.data.get(\"tools\",{}).get(\"messages\",[])\n",
    "        if assistant_node:\n",
    "            print(\"-\"*20 + \" Assistant Node \" + \"-\"*20)\n",
    "            print(assistant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\"*20 + \" Tool Node \" + \"-\"*20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  1efd3466-46ad-6fea-8004-0dfaeaad452c\n",
      "Num Messages:  4 Next:  []\n",
      "ID:  1efd3466-4379-6c3d-8003-01ed711170a1\n",
      "Num Messages:  3 Next:  ['assistant']\n",
      "ID:  1efd3466-436d-68ec-8002-4681272c8d94\n",
      "Num Messages:  2 Next:  ['tools']\n",
      "ID:  1efd3459-505d-64f3-8001-12b64d1efb38\n",
      "Num Messages:  1 Next:  ['assistant']\n",
      "ID:  1efd344f-0af7-681e-8003-0033b015937c\n",
      "Num Messages:  4 Next:  []\n",
      "ID:  1efd344f-07cc-6abc-8002-2548b5c96f0c\n",
      "Num Messages:  3 Next:  ['assistant']\n",
      "ID:  1efd344f-07a1-6eb3-8001-5d5bfa89b4fc\n",
      "Num Messages:  2 Next:  ['tools']\n",
      "ID:  1efd344e-d704-6a39-8000-cb5806fd96a3\n",
      "Num Messages:  1 Next:  ['assistant']\n",
      "ID:  1efd344e-d6fd-621c-bfff-cf5605717a9c\n",
      "Num Messages:  0 Next:  ['__start__']\n"
     ]
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "\n",
    "for state in states:\n",
    "    print(\"ID: \", state[\"checkpoint\"][\"checkpoint_id\"])\n",
    "    print(\"Num Messages: \", len(state[\"values\"][\"messages\"]), \"Next: \", state[\"next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-academy-GSfDBkeK-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
