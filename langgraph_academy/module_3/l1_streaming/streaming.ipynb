{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, we built a deeper understanding of both state and memory.\n",
    "\n",
    "We built up a Chatbot with external memory (Postgres Checkpointer) that can sustain long-running conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "This module we dive into `human-in-the-loop`, which builds on memory and allows users to interact with agents.\n",
    "\n",
    "To set the stage for `human-in-the-loop`, we're going to first deep dive into streaming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from IPython.display import display, Image\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START,END, MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, RemoveMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Streaming\n",
    "\n",
    "LangGraph is built with first class support for streaming.\n",
    "\n",
    "Let's setup our Chatbot from MModule 2, and show how this can be used with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperaature=0.8,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    summary:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: State):\n",
    "\n",
    "    summary = state.get(\"summary\",\"\")\n",
    "\n",
    "    if summary:\n",
    "\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        \"messages\":response\n",
    "    }\n",
    "\n",
    "def summarize_conversattion(state: State):\n",
    "\n",
    "    summary = state.get(\"summary\",\"\")\n",
    "\n",
    "    if summary:\n",
    "\n",
    "        system_message = f\"This is the current conversation summary: {summary}. \\n Extend the summary by taking into account the new messages above:\"\n",
    "\n",
    "    else:\n",
    "        system_message = \"Create a conversation summary given the messages above:\"\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=system_message)]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Delete the messages\n",
    "    recent_messages = [RemoveMessage(id=m.id) for m in state['messages'][-2:]]\n",
    "\n",
    "    return {\n",
    "        \"summary\": response.content, messages: recent_messages\n",
    "    }\n",
    "\n",
    "def should_continue(state: State):\n",
    "\n",
    "    messages = state['messages']\n",
    "    if len(messages) > 6:\n",
    "        return 'summarize_conversation'\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(\"conversation\", call_model)\n",
    "builder.add_node(\"summarize_conversation\",summarize_conversattion)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"conversation\"),\n",
    "builder.add_conditional_edges(\"conversation\", should_continue)\n",
    "builder.add_edge(\"summarize_conversation\",END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Full State\n",
    "\n",
    "Now let's talk about ways to stream our graph state.\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results.\n",
    "\n",
    "LangGraph supports a few different streaming modes for graph state:\n",
    "\n",
    "- `values`: This streams the full state of the graph after each node is called.\n",
    "- `updates`: This streams updates of the state of the graph after each node is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../assets/streaming.png\" width=900 alt=\"streaming\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after each step of the graph.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` has the key and the updated state s the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\":\"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Olá Guilherme! (That\\'s \"hello\" in Portuguese!) It\\'s nice to meet you. I\\'m here to chat and help with any questions or topics you\\'d like to discuss. Where are you from? Are you originally from Brazil, where Portuguese is the official language?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-01-07T17:31:32.4014627Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6022861500, 'load_duration': 4413134700, 'prompt_eval_count': 21, 'prompt_eval_duration': 300000000, 'eval_count': 59, 'eval_duration': 1307000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b6053848-d1f5-4d51-87c4-e67d9f7106d2-0', usage_metadata={'input_tokens': 21, 'output_tokens': 59, 'total_tokens': 80})}}\n"
     ]
    }
   ],
   "source": [
    "#Start the conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"Hello, my name is Guilherme Toso!\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the state updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Guilherme! Since we just started our conversation, feel free to share a bit about yourself: what do you like to talk about or discuss? Are you interested in learning something new, or perhaps sharing your hobbies and interests with me?\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"messages\":[HumanMessage(\"Hello, I'm Guilherme!\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation']['messages'].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new thread\n",
    "config = {\"configurable\":{\"thread_id\":\"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, My name is Guilherme Toso!\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, My name is Guilherme Toso!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Olá Guilherme! (That's \"hello\" in Portuguese!) Nice to meet you! I don't have any information about a specific person named Guilherme Toso, so this is the start of our conversation. How can I assist or chat with you today? Are there any topics on your mind that you'd like to discuss?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation again\n",
    "input_message = HumanMessage(content=\"Hello, My name is Guilherme Toso!\")\n",
    "for event in graph.stream({\"messages\":[input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event[\"messages\"]:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Tokens\n",
    "\n",
    "But, we often want to stream more that state.\n",
    "\n",
    "In particular, with LLM calls it is common to stream tthe tokens as they are generated.\n",
    "\n",
    "We can do this using the `.astream_events` method, which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    "\n",
    "- `event`: This is the type of event that is being emitted.\n",
    "- `name`: This is the name of the event.\n",
    "- `data`: This is the data associated with the event.\n",
    "- `metadatta`: Which contains `langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: None. Type: on_chain_start. Name: LangGraph\n",
      "Node: __start__. Type: on_chain_start. Name: __start__\n",
      "Node: __start__. Type: on_chain_start. Name: _write\n",
      "Node: __start__. Type: on_chain_end. Name: _write\n",
      "Node: __start__. Type: on_chain_start. Name: _write\n",
      "Node: __start__. Type: on_chain_end. Name: _write\n",
      "Node: __start__. Type: on_chain_stream. Name: __start__\n",
      "Node: __start__. Type: on_chain_end. Name: __start__\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOllama\n",
      "Node: conversation. Type: on_chain_start. Name: _write\n",
      "Node: conversation. Type: on_chain_end. Name: _write\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: None. Type: on_chain_stream. Name: LangGraph\n",
      "Node: None. Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about quantum physics!\")\n",
    "async for event in graph.astream_events({\"messages\":[input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event[\"metadata\"].get(\"langgraph_node\")}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event[\"metadata\"][\"langgraph_node\"]` to select the node to stream from.\n",
    "\n",
    "And we can use `event[\"data\"]` to get the actual data for each event, which in this case is an `AIMessageChunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='You', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=\"'re\", additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' referring', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' fascinating', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' laws', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' all', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' physics', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='!\\n\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='Newton', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' Third', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' Law', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' Law', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' Action', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' Reaction', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' states', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='For', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' every', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' action', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' there', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' equal', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' opposite', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' reaction', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.\"', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='In', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' words', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' push', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' pull', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' something', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' it', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' will', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' always', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' push', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' pull', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' back', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' same', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' law', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' applies', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' all', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' interactions', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' objects', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' contact', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' forces', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='like', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' pushing', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' wall', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' non', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='-contact', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' forces', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='like', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' gravitational', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' attraction', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=').\\n\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' examples', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='You', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' kick', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' ball', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' ball', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' ex', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='erts', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' equal', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' opposite', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' your', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' foot', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='A', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' car', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' acceler', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='ates', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' forward', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' road', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' ex', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='erts', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' equal', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' opposite', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' backwards', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' car', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' prop', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='elling', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' it', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' forward', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='You', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' throw', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' stone', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' upwards', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='**:', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' stone', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' ex', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='erts', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' equal', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' opposite', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' force', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' downwards', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' your', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' hand', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='This', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' law', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' far', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='-reaching', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' implications', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' many', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' areas', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' physics', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' mechanics', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' therm', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='odynamics', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' even', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content=' astronomy', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-3830a524-a989-49e7-9036-aa92227cf15f')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-01-07T18:11:14.905104Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4356280200, 'load_duration': 23450900, 'prompt_eval_count': 22, 'prompt_eval_duration': 208000000, 'eval_count': 200, 'eval_duration': 4123000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-3830a524-a989-49e7-9036-aa92227cf15f', usage_metadata={'input_tokens': 22, 'output_tokens': 200, 'total_tokens': 222})}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream=\"conversation\"\n",
    "config = {\"configurable\":{\"thread_id\":\"222\"}}\n",
    "input_message = HumanMessage(content=\"Tell me something about the third law of physics by Newton!\")\n",
    "async for event in graph.astream_events({\"messages\":[input_message]}, config, version=\"v2\"):\n",
    "    if event['event'] == \"on_chat_model_stream\" and event['metadata'].get(\"langgraph_node\") == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Newton's Third Law states:\n",
      "\n",
      "**\"To every action, there is an equal and opposite reaction.\"**\n",
      "\n",
      "This means that when one object exerts a force on another object, the second object will always exert an equal and opposite force on the first object. The forces are of equal magnitude but in opposite directions.\n",
      "\n",
      "For instance:\n",
      "\n",
      "* When you throw a ball upwards, the ball exerts an upward force on your hand, and your hand exerts an equal downward force on the ball.\n",
      "* When a boat pushes against the water to move forward, the water pushes back against the boat with equal force.\n",
      "* When a rocket engine fires, it expels hot gases in one direction, and the rocket moves in the opposite direction with equal speed.\n",
      "\n",
      "This law is essential for understanding many physical phenomena, from the motion of objects on Earth to the behavior of celestial bodies in space."
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"222\"}}\n",
    "input_message = HumanMessage(content=\"Tell me something about the third law of physics by Newton!\")\n",
    "async for event in graph.astream_events({\"messages\":[input_message]}, config, version=\"v2\"):\n",
    "    if event['event'] == \"on_chat_model_start\" and event['metadata'].get(\"langgraph_node\") == node_to_stream:\n",
    "        print(\"AI:\", end=\" \")\n",
    "    if event['event'] == \"on_chat_model_stream\" and event['metadata'].get(\"langgraph_node\") == node_to_stream:\n",
    "        data = event['data']\n",
    "        print(data[\"chunk\"].content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming with LangGraph API\n",
    "\n",
    "Our Chatbot is deployed locally to Studio and the LangGraph API serves as the backend for Studio.\n",
    "\n",
    "We can interact with the API via the LangGraph SDK.\n",
    "\n",
    "Let's get th URL for the local deployment from Stusdio: ` http://127.0.0.1:2024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '166c0d22-706c-5a5b-9027-ea37f7308a85',\n",
       "  'graph_id': 'react',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'react',\n",
       "  'created_at': '2024-12-29T16:26:28.065150+00:00',\n",
       "  'updated_at': '2024-12-29T16:26:28.065150+00:00',\n",
       "  'version': 1},\n",
       " {'assistant_id': '228f9934-0cdd-5383-92c8-ee8422522cc2',\n",
       "  'graph_id': 'router',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'router',\n",
       "  'created_at': '2024-12-29T16:26:27.689297+00:00',\n",
       "  'updated_at': '2024-12-29T16:26:27.689297+00:00',\n",
       "  'version': 1},\n",
       " {'assistant_id': '608f7b9c-04e5-5cf2-a3f7-ba75a3719808',\n",
       "  'graph_id': 'chain',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'chain',\n",
       "  'created_at': '2024-12-29T16:26:27.316657+00:00',\n",
       "  'updated_at': '2024-12-29T16:26:27.316657+00:00',\n",
       "  'version': 1},\n",
       " {'assistant_id': '5e0f6b46-d00f-5af4-87dc-ea2105ff526d',\n",
       "  'graph_id': 'simple',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'simple',\n",
       "  'created_at': '2024-12-26T19:57:43.536734+00:00',\n",
       "  'updated_at': '2024-12-26T19:57:43.536734+00:00',\n",
       "  'version': 1}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "URL=\"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Assistants\n",
    "assistants = await client.assistants.search()\n",
    "assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stream `values` like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1efcd283-d89d-6b47-b20c-c1f0fa615525', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '79dd21f5-65c2-426a-8465-0eba8ea2563b', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '79dd21f5-65c2-426a-8465-0eba8ea2563b', 'example': False}, {'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-07T18:50:24.4321953Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3187571300, 'load_duration': 1901753100, 'prompt_eval_count': 375, 'prompt_eval_duration': 256000000, 'eval_count': 22, 'eval_duration': 463000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-75139dcd-c12e-4856-aa7d-082c73c97fed-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '87bd035d-344c-4e17-905d-5bdb29ec0393', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 375, 'output_tokens': 22, 'total_tokens': 397}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '79dd21f5-65c2-426a-8465-0eba8ea2563b', 'example': False}, {'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-07T18:50:24.4321953Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3187571300, 'load_duration': 1901753100, 'prompt_eval_count': 375, 'prompt_eval_duration': 256000000, 'eval_count': 22, 'eval_duration': 463000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-75139dcd-c12e-4856-aa7d-082c73c97fed-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '87bd035d-344c-4e17-905d-5bdb29ec0393', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 375, 'output_tokens': 22, 'total_tokens': 397}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '6e561006-60fb-40ad-998a-f3838f2112e8', 'tool_call_id': '87bd035d-344c-4e17-905d-5bdb29ec0393', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '79dd21f5-65c2-426a-8465-0eba8ea2563b', 'example': False}, {'content': '', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-07T18:50:24.4321953Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3187571300, 'load_duration': 1901753100, 'prompt_eval_count': 375, 'prompt_eval_duration': 256000000, 'eval_count': 22, 'eval_duration': 463000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-75139dcd-c12e-4856-aa7d-082c73c97fed-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '87bd035d-344c-4e17-905d-5bdb29ec0393', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 375, 'output_tokens': 22, 'total_tokens': 397}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '6e561006-60fb-40ad-998a-f3838f2112e8', 'tool_call_id': '87bd035d-344c-4e17-905d-5bdb29ec0393', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-07T18:50:24.7741959Z', 'done': True, 'done_reason': 'stop', 'total_duration': 326076900, 'load_duration': 13045900, 'prompt_eval_count': 161, 'prompt_eval_duration': 17000000, 'eval_count': 14, 'eval_duration': 293000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, 'type': 'ai', 'name': None, 'id': 'run-9d277f6a-1d31-4f7b-9897-ad8102fd6eba-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 161, 'output_tokens': 14, 'total_tokens': 175}}]})\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"react\", input={\n",
    "    \"messages\": [input_message]\n",
    "}, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streamed objects have:\n",
    "\n",
    "- `event`: Type\n",
    "- `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "content='Multiply 2 and 3.' additional_kwargs={'additional_kwargs': {'additional_kwargs': {}, 'response_metadata': {}, 'example': False}, 'response_metadata': {}, 'example': False} response_metadata={} id='11893e5f-f1bc-4fe4-869b-ef874bf38eb9'\n",
      "---------------------------------------------------------------------------\n",
      "content='' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-07T18:55:04.6796013Z', 'done': True, 'done_reason': 'stop', 'total_duration': 753573600, 'load_duration': 14106800, 'prompt_eval_count': 376, 'prompt_eval_duration': 188000000, 'eval_count': 22, 'eval_duration': 549000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 376, 'output_tokens': 22, 'total_tokens': 398}} response_metadata={} id='run-7c5346d0-8647-4a27-b334-77dafdf26674-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '955d070d-3ecb-40e9-887d-5fe983d1e550', 'type': 'tool_call'}]\n",
      "---------------------------------------------------------------------------\n",
      "content='6' name='multiply' id='a64367c7-8b11-4546-aeef-71942deed0bc' tool_call_id='955d070d-3ecb-40e9-887d-5fe983d1e550'\n",
      "---------------------------------------------------------------------------\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.1-tool', 'created_at': '2025-01-07T18:55:05.0168351Z', 'done': True, 'done_reason': 'stop', 'total_duration': 325542400, 'load_duration': 15326700, 'prompt_eval_count': 162, 'prompt_eval_duration': 8000000, 'eval_count': 14, 'eval_duration': 300000000, 'message': {'role': 'assistant', 'content': 'The result of multiplying 2 and 3 is 6.', 'images': None, 'tool_calls': None}}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 162, 'output_tokens': 14, 'total_tokens': 176}} response_metadata={} id='run-a61ad2dc-a9ac-4090-852d-3c7f8f51515a-0'\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3.\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"react\", input={\"messages\":[input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get(\"messages\",None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can use `messages` mod to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph that is a list of messages.\n",
    "\n",
    "All events emitted have two attributes:\n",
    "\n",
    "- `event`: This is the name of the event.\n",
    "- `data`: This is data associated with the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3.\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"react\", input={\"messages\":[input_message]}, stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can  see a few events:\n",
    "\n",
    "- `metadata`: metadata about the run.\n",
    "- `messages/complete`: fully formed message.\n",
    "- `messages/partial`: LLM Tokens\n",
    "\n",
    "Now, let's show how stream these messages.\n",
    "\n",
    "The nice thing is that we can get token-wise streaming of partial messages!\n",
    "\n",
    "We'll define a helper function for better formtting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1efcd2b8-22f0-60e8-aad2-85a5393284ce\n",
      "--------------------------------------------------\n",
      "Tool Calls\n",
      "Tool Call Id: 30f26889-9e6b-4df2-9440-385aa7fc1c52, Funcion: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls\n",
      "Tool Call Id: 30f26889-9e6b-4df2-9440-385aa7fc1c52, Funcion: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3.\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(f\"Tool Call Id: {call['id']}, Funcion: {call['name']}, Arguments: {call['args']}\")\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tools called\"\n",
    "\n",
    "async for event in client.runs.stream(thread['thread_id'], assistant_id=\"react\", input={\"messages\":[input_message]}, stream_mode=\"messages\"):\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data[\"run_id\"]}\")\n",
    "        print(\"--\"*25)\n",
    "\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item[\"content\"]}\")\n",
    "            else:\n",
    "                tool_calls = data_item.get(\"tool_calls\",[])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\",[])\n",
    "                content = data_item.get(\"content\",\"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\",{})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "                \n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish reason\",\"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-academy-GSfDBkeK-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
